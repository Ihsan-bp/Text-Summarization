# Text-Summarization
<h3>Introduction</h3>
Text summarization is a challenging task in natural language processing that aims to generate concise and coherent summaries from large pieces of text. In this report, we present an approach using the T5 and BART models for text summarization. We discuss the results obtained from both models and explore their potential applications.

<h3>Approach</h3>
The objective of this project is to conduct a comparative analysis of two prominent OpenAI Language Models (OpenLLMs) – T5 and BART – within the context of text summarization. The project initiates with the acquisition of a suitable dataset comprising news articles and their corresponding reference summaries, further divided into training, testing, and validation sets. Following model selection and configuration, both T5 and BART are employed to generate summaries for a representative subset of news articles, ensuring adherence to model-specific best practices. To assess the summarization quality rigorously, the project utilizes ROUGE scores, a well-established performance metric. The comparative analysis of ROUGE scores, spanning metrics such as recall, precision, and F1-score, aids in determining which model excels in encapsulating the essence of the reference summaries. In addition to quantitative metrics, user interaction is introduced, enabling users to input text and receive summaries generated by both models, offering insights into real-world usability. The ultimate goal is to recommend the most effective OpenLLM for text summarization, with considerations encompassing overall performance, user-friendliness, and computational efficiency, thus facilitating practical applications in real-world scenarios.
<b>Data Preparation:</b> We gathered a dataset consisting of news articles with corresponding highlights. The dataset was preprocessed to remove any unnecessary information and ensure the articles were in a suitable format for summarization.

<h3>Model</h3>
<h3>T5</h3>
We utilized the T5 model, specifically the "Einmalumdiewelt/T5-Base_GNAD" variant, for text summarization.
The T5 tokenizer was used to tokenize the articles and generate input tokens.
We implemented the "t5_summarize" function to generate summaries using the T5 model with adjustable parameters such as the number of beams and the maximum number of words in the summary.
We evaluated the T5 model's performance using the ROUGE scores, which measure the quality of the generated summaries compared to reference summaries.
<h3>BART</h3>
We employed the BART model, specifically the "facebook/bart-large-cnn" variant, for text summarization.
The BART tokenizer was used to tokenize the articles and create input tokens.
We implemented the "bart_summarize" function to generate summaries using the BART model with adjustable parameters.
The BART model's performance was also evaluated using ROUGE scores.
<h3>Results</h3>
Here are the ROUGE scores for both models:

For the T5 model:

1. ROUGE-1 F1-score: 0.507
2. ROUGE-2 F1-score: 0.265
3. ROUGE-L F1-score: 0.478

For the BART model:

1. ROUGE-1 F1-score: 0.5610
2. ROUGE-2 F1-score: 0.3111
3. ROUGE-L F1-score: 0.5610
<h3>Discussion</h3>
It's evident that the BART model outperforms the T5 model across all three ROUGE metrics (ROUGE-1, ROUGE-2, and ROUGE-L) in terms of F1-score. Therefore, based on these ROUGE scores, the BART model is the better-performing model for generating summaries in the given context. It has higher precision, recall, and F1-scores for all three ROUGE measures, indicating better overall summary quality.

<h3>Applications</h3>
The automatic text summarization approach using the T5 and BART models has various potential applications:
News Aggregation: Summarizing news articles can help users quickly get an overview of current events without reading entire articles.
Document Summarization: Summarizing lengthy documents or research papers can assist researchers and professionals in identifying key information efficiently.
Social Media Analysis: Summarizing user-generated content on social media platforms can aid in understanding trends, sentiment analysis, and monitoring discussions.
Content Generation: Summarization models can be utilized as part of content generation systems to produce concise summaries of generated text.

<h3>Conclusion</h3>
In conclusion, based on the performance metrics obtained from comparing two OpenAI language models (T5 and BART) on a text summarization task, the BART model has consistently outperformed the T5 model across all key ROUGE scores (ROUGE-1, ROUGE-2, and ROUGE-L). The BART model achieved higher F1-scores, indicating better precision and recall in generating summaries. Therefore, the recommendation for the best model for the text summarization task is the BART model, as it has demonstrated superior performance in generating high-quality summaries according to the provided metrics.
